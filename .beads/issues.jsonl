{"id":"RAG-0yf","title":"get_page_context Tool (Active Verification)","description":"Neues MCP Tool: get_page_context(document, page, context_window=500). Gibt rohen Text einer Seite zurück. Agent verifiziert Zitate selbst BEVOR er sie dem User gibt. Erhöht Vertrauenswürdigkeit. Source: Session Evaluation","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:49.32509+01:00","updated_at":"2026-01-05T03:51:49.32509+01:00"}
{"id":"RAG-16r","title":"PDF Pipeline: In-place cleanup statt raw+cleaned","description":"Wenn md-cleanup-master Agent stabil: raw.md direkt cleanen statt cleaned.md erstellen. Spart Speicher, weniger Duplikation.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T18:54:51.738432+01:00","updated_at":"2025-12-30T18:54:51.738432+01:00"}
{"id":"RAG-221","title":"Look Before Leap + Semantic Routing (Skill)","description":"Skill Instruction: (1) Agent ruft list_collections zu Beginn jeder Session auf. (2) Semantic Routing: Academic concepts → Paper Collection. Technical definitions → Postgres docs. Source: Session Evaluation","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:42.599917+01:00","updated_at":"2026-01-05T03:51:42.599917+01:00"}
{"id":"RAG-27f","title":"Result Clustering: Merge adjacent chunks","description":"Diversity Re-Ranking im MCP. Problem: top_k Treffer oft aus demselben Absatz (redundant). Lösung: Bei 20 DB-Treffern prüfen ob Chunks Nachbarn sind (ID 40+41). Wenn ja: zu einem Cluster mergen. Return: Statt 5 Einzel-Chunks 'Cluster' mit breiteren Kontext. Vorteil: Agent sieht mehr vom Dokument pro Call, erhöht Chance auf richtiges Stichwort für Ctrl+F.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-04T03:06:34.708861+01:00","updated_at":"2026-01-04T03:06:34.708861+01:00"}
{"id":"RAG-5cg","title":"Indexer: BATCH_SIZE erhöhen","description":"BATCH_SIZE in indexer.py von 1 auf höheren Wert erhöhen. Aktuell: jeder Chunk einzeln embedded = langsam.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T18:54:51.263955+01:00","updated_at":"2025-12-31T02:23:14.032242+01:00","closed_at":"2025-12-31T02:23:14.032242+01:00","close_reason":"BATCH_SIZE auf 32 erhöht, Hardware-Info in README"}
{"id":"RAG-67k","title":"Llama Embedding Server Check","description":"Check llama.cpp embedding server performance and configuration. Current: BATCH_SIZE=1, 413 chunks took significant time.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T18:29:28.405237+01:00","updated_at":"2025-12-31T02:08:48.468875+01:00","closed_at":"2025-12-31T02:08:48.468875+01:00","close_reason":"Upgraded to Q8_0 model + added -ngl 99 GPU offload. SOTA config documented in README."}
{"id":"RAG-6gf","title":"PDF-zu-MD Pipeline mit MinerU integrieren","description":"MinerU (${MINERU_PATH}) für PDF→MD Konvertierung. Klären: Wie Dateinamen/Quellzuordnung in Vector DB tracken?","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T17:45:25.939956+01:00","updated_at":"2025-12-29T00:20:53.323632+01:00","closed_at":"2025-12-29T00:20:53.323632+01:00","close_reason":"Pipeline-Refactoring abgeschlossen. PDF -\u003e MD -\u003e chunks.json -\u003e pgvector Flow implementiert.","comments":[{"id":1,"issue_id":"RAG-6gf","author":"brunowinter2000","text":"Slash Command pdf-to-rag.md + md-cleanup agent erstellt. Test mit echter PDF offen.","created_at":"2025-12-28T17:33:00Z"},{"id":2,"issue_id":"RAG-6gf","author":"brunowinter2000","text":"Pre-Cleanup (postprocess.py) + Chunk-basiertes LLM-Cleanup implementiert. Mineru workflow.py erstellt. Test mit echter PDF noch offen.","created_at":"2025-12-28T18:38:10Z"}]}
{"id":"RAG-6u7","title":"workflow.py CLI: --collection, --document args","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-01T03:41:05.595577+01:00","updated_at":"2026-01-02T00:33:54.421803+01:00","closed_at":"2026-01-02T00:33:54.421803+01:00","close_reason":"Implemented --collection and --document filters for search command","comments":[{"id":8,"issue_id":"RAG-6u7","author":"brunowinter2000","text":"MCP Tool hat --collection und --document Filter. workflow.py CLI sollte diese auch haben für Konsistenz.","created_at":"2026-01-01T02:41:10Z"}]}
{"id":"RAG-8if","title":"docker-compose: pgvector Extension auto-enable","description":"Init-Script in docker-compose.yml hinzufügen das CREATE EXTENSION vector automatisch ausführt bei DB-Start.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T18:54:51.500038+01:00","updated_at":"2025-12-31T02:17:42.395055+01:00","closed_at":"2025-12-31T02:17:42.395055+01:00","close_reason":"Won't fix - Volume existiert bereits, Extension manuell aktiviert. Kein akuter Bedarf."}
{"id":"RAG-8ni","title":"Score Threshold + Rerank","description":"Retrieval Pre-filtering: top-20 by vector → filter score \u003e0.7 → deduplicate → top-5. Optional: Cross-Encoder Reranking nach BM25+Vector. Reduziert Token-Count um 40%. Source: Reddit Enterprise RAG Thread","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:00.524753+01:00","updated_at":"2026-01-05T03:51:00.524753+01:00"}
{"id":"RAG-8pl","title":"BM25 search_keyword references missing tsv column","description":"Agent discovered: retriever.py search_keyword uses tsv column for full-text search, but indexer.py schema doesn't create it. BM25 search will fail at runtime. Need to either add tsv column to schema or fix retriever logic.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-03T18:15:56.431625+01:00","updated_at":"2026-01-03T18:15:56.431625+01:00"}
{"id":"RAG-9jm","title":"Hybrid Search (BM25 + Vector)","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-02T20:51:30.4547+01:00","updated_at":"2026-01-03T03:28:45.46198+01:00","closed_at":"2026-01-03T03:28:45.46198+01:00","close_reason":"Implemented search_keyword (BM25) as separate MCP tool. Added tsvector column + GIN index. Agent can now choose between semantic (search) and keyword (search_keyword) based on user intent.","comments":[{"id":14,"issue_id":"RAG-9jm","author":"brunowinter2000","text":"Combine BM25 keyword search with vector similarity. Use reranking (cross-encoder) to filter semantic misses like TOC matches. Consider pg_trgm or ts_vector for BM25.","created_at":"2026-01-02T19:51:38Z"}]}
{"id":"RAG-aj4","title":"Fail-Safe Collection Routing + Alias-Resolver","description":"(1) Alias Map: paper→Learning-based, thesis→Learning-based, spec→specification, postgres→postgresql-17-US. (2) Bei unbekannter Collection: Error mit available_collections + suggestion statt (empty). Source: Session Evaluation","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:22.029265+01:00","updated_at":"2026-01-05T03:51:22.029265+01:00"}
{"id":"RAG-gsi","title":"read_document Tool","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-02T21:15:25.541248+01:00","updated_at":"2026-01-02T23:52:07.620089+01:00","closed_at":"2026-01-02T23:52:07.620089+01:00","close_reason":"Implemented read_document tool with merge_chunks overlap deduplication","comments":[{"id":16,"issue_id":"RAG-gsi","author":"brunowinter2000","text":"New MCP tool: read_document(collection, document, start_chunk, num_chunks). Allows reading continuous text from a known position. Use case: After search finds relevant chunk, read forward to get full context/story.","created_at":"2026-01-02T20:15:35Z"}]}
{"id":"RAG-idq","title":"Hierarchical Chunks: Multi-Level","description":"Multi-Level Chunking: Document Level (title, authors, date, type) → Section Level (Abstract, Methods, Results) → Paragraph Level (200-400 tokens) → Sentence Level (für Precision Queries). Query triggers drill-down bei low confidence. Source: Reddit Enterprise RAG Thread","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:14.578398+01:00","updated_at":"2026-01-05T03:51:14.578398+01:00"}
{"id":"RAG-jsv","title":"Mineru MLX Backend + workflow.py CLI-Flags","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-02T19:02:52.380573+01:00","updated_at":"2026-01-03T01:52:24.566557+01:00","closed_at":"2026-01-03T01:52:24.566557+01:00","close_reason":"Scope macht keinen Sinn - Mineru ist separates Tool, gehört nicht in RAG workflow.py","comments":[{"id":11,"issue_id":"RAG-jsv","author":"brunowinter2000","text":"Test vlm-mlx-engine backend für M4 Pro. Dann workflow.py erweitern: --backend, --method, --lang Flags exposen. Expected: 2-5x speedup.","created_at":"2026-01-02T18:03:03Z"}]}
{"id":"RAG-koy","title":"README Tech Stack dokumentieren","description":"Docker, PostgreSQL+pgvector, Qwen3-Embedding-8B, llama.cpp Server, FastMCP - Stack in README beschreiben.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T17:45:31.475547+01:00","updated_at":"2025-12-28T23:21:21.723923+01:00","closed_at":"2025-12-28T23:21:21.723923+01:00","close_reason":"README.md mit vollständigem Tech Stack aktualisiert"}
{"id":"RAG-o44","title":"Auto-start llama.cpp embedding server","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T00:13:30.436164+01:00","updated_at":"2026-01-03T00:34:55.243553+01:00","closed_at":"2026-01-03T00:34:55.243553+01:00","close_reason":"Implemented: embedder.py auto-starts llama-server when not running","comments":[{"id":17,"issue_id":"RAG-o44","author":"brunowinter2000","text":"Implementation: Health-check in embedder.py beim ersten Aufruf. Wenn localhost:8081/health nicht ok -\u003e start.sh ausführen via subprocess. Dann SKILL.md cleanup (manuelle Anleitung entfernen).","created_at":"2026-01-02T23:13:37Z"}]}
{"id":"RAG-or9","title":"Heading Metadata Extraction","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-02T20:51:30.241716+01:00","updated_at":"2026-01-03T16:17:27.704482+01:00","closed_at":"2026-01-03T16:17:27.704482+01:00","close_reason":"Not needed - heading structure inconsistent across docs, especially for crawled websites","comments":[{"id":13,"issue_id":"RAG-or9","author":"brunowinter2000","text":"Extract chapter/section from Markdown headings during chunking. Store as metadata in documents table. Enable filtering by chapter/section in search.","created_at":"2026-01-02T19:51:37Z"},{"id":19,"issue_id":"RAG-or9","author":"brunowinter2000","text":"Implementation Plan:\n\n1. chunker.py: Track current heading while chunking, add 'heading' field to chunks\n2. chunks.json: Add heading field per chunk\n3. indexer.py: Add 'heading TEXT' column to schema, store in store_chunks()\n4. retriever.py: Return heading in search results\n5. format_results: Show 'Chapter: X' in output\n\nFiles: chunker.py, indexer.py, retriever.py, pdf-convert.md\nMigration: Re-index required after schema change","created_at":"2026-01-03T00:28:22Z"}]}
{"id":"RAG-owo","title":"Query Routing: Complexity Detection","description":"Query Complexity Detection: Broad/fuzzy queries → Paragraph-level + Semantic search. Precise/technical queries (trigger: exact, specific, table, Zahlen) → Sentence-level + Keyword+Table lookup. Kann Skill-seitig oder Tool-seitig implementiert werden. Source: Reddit Enterprise RAG Thread","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:07.101002+01:00","updated_at":"2026-01-05T03:51:07.101002+01:00"}
{"id":"RAG-p3s","title":"Terminology Filtering (Skill)","description":"Skill-seitig: Agent prüft RAG-Schnipsel gegen Terminology-Tabelle VOR Ausgabe. Abfrage im RAG-Text → in Terminology Abfrage=Forbidden → ersetze durch Query. Source: Session Evaluation","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:36.272113+01:00","updated_at":"2026-01-05T03:51:36.272113+01:00"}
{"id":"RAG-peu","title":"RAG Indexer Speedup Validation (Benchmark)","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-02T19:02:52.603528+01:00","updated_at":"2026-01-03T01:52:24.774611+01:00","closed_at":"2026-01-03T01:52:24.774611+01:00","close_reason":"Speedup bereits validiert","comments":[{"id":12,"issue_id":"RAG-peu","author":"brunowinter2000","text":"embedder.py fix: tokenize API calls entfernt, char-basierte Schätzung statt dessen. Benchmark: Re-run index-json mit 9452 chunks, compare old (~45min) vs new (expected 5-10min).","created_at":"2026-01-02T18:03:03Z"}]}
{"id":"RAG-qfq","title":"HyDE: Hypothetical Document Embeddings","description":"Agent-/Skill-seitige Verbesserung. Problem: Keyword-Suche scheitert wenn Text andere Wörter benutzt (Frage: 'Wie funktioniert CBO?' aber Text: 'The planner estimates path costs'). Lösung: Agent halluziniert zuerst eine perfekte Antwort, dann sucht er mit dieser Antwort als Query. Halluzinierte Antwort ist semantisch näher am echten Text als die Frage. Findet Konzepte statt Keywords.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-04T03:06:35.152709+01:00","updated_at":"2026-01-04T03:06:35.152709+01:00","comments":[{"id":20,"issue_id":"RAG-qfq","author":"brunowinter2000","text":"Implementiert in SKILL.md (HyDE Pattern Section + Decision Guide). Noch nicht getestet.","created_at":"2026-01-05T02:50:37Z"}]}
{"id":"RAG-qj3","title":"md-cleanup edge cases","description":"Remaining issues in cleaned.md after md-cleanup-master run:\n\nOCR Issues (5):\n- Line 982: 1_suppkey → l_suppkey\n- Line 1130: 1_orderkey, 1_receiptdate\n- Line 1467: 11.1_orderkey alias corruption  \n- Line 1898: 0_KEY → O_KEY\n- Line 3600: 1 commitdate → l_commitdate\n\nLaTeX (2):\n- Line 2290: mathbf xi in SQL\n- Line 2722: Throughput formula\n\nFix options: iterate md-cleanup, extend clean_pdf.py, or defer to per-chunk LLM","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-30T01:23:45.734315+01:00","updated_at":"2025-12-31T03:06:49.539722+01:00","comments":[{"id":6,"issue_id":"RAG-qj3","author":"brunowinter2000","text":"## Reproducible Test Procedure\n\n### Setup\n```bash\n# Ensure clean state\nrm -f data/documents/specification/raw_cleaned.md\nrm -f data/documents/specification/cleaned.md\nls data/documents/specification/  # Should only show: chunks.json, chunks_raw.json, raw.md\n```\n\n### Test Run\n```bash\n# Launch md-cleanup-master with new constraints\n# (Prompt template from agent-dispatch SKILL.md)\n```\n\nPrompt:\n```\nClean the PDF-converted markdown at ./data/documents/specification/raw.md\n\nSAFETY CONSTRAINTS:\n1. Before ANY changes: verify line count (wc -l). After changes: check again.\n   If line count drops \u003e1%, REVERT immediately (git checkout).\n2. Do NOT read full file (\u003e250KB). Use grep -nC 3 to inspect patterns locally.\n3. Regex MUST be surgical: use word boundaries (\\b1_orderkey\\b → l_orderkey).\n   NEVER use greedy wildcards (.*) that span lines.\n4. After cleanup: verify SQL syntax intact (WHERE x = y operators preserved).\n\nKnown issues:\n- OCR: 1/l confusion (1_suppkey → l_suppkey, 1_orderkey → l_orderkey)\n- OCR: 0/O confusion (0_KEY → O_KEY)\n- LaTeX: mathbf, prime remnants in SQL\n```\n\n### Validation\n```bash\n# Check remaining issues\ngrep -c \"1_suppkey\\|1_orderkey\\|0_KEY\\|mathbf\" data/documents/specification/raw_cleaned.md\n\n# Line count integrity\nwc -l data/documents/specification/raw.md\nwc -l data/documents/specification/raw_cleaned.md\n```\n\n### Success Criteria\n- Line count: ±1% of original (3842 lines)\n- OCR issues: 0 (was 5)\n- LaTeX issues: ≤2 (was 7)\n- No trial-and-error loops (agent should succeed on first attempt)","created_at":"2025-12-31T01:44:57Z"},{"id":7,"issue_id":"RAG-qj3","author":"brunowinter2000","text":"Ongoing: Dokumentiert md-cleanup Versuchsaufbau. TPC-H spec cleaned, weitere MDs ausstehend.","created_at":"2025-12-31T02:06:56Z"},{"id":10,"issue_id":"RAG-qj3","author":"brunowinter2000","text":"Fixed in SKILL.md + md-cleanup.md: (1) LaTeX now UNWRAPs arguments instead of deleting them, (2) Dictionary now uses /usr/share/dict/words + document vocab instead of hardcoded 50-word list","created_at":"2026-01-02T18:01:00Z"},{"id":18,"issue_id":"RAG-qj3","author":"brunowinter2000","text":"Renamed scope: Cleanup Pipeline Improvement (ongoing) - includes noise filtering, edge cases, incremental improvements to md-cleanup agent","created_at":"2026-01-02T23:52:26Z"}]}
{"id":"RAG-run","title":"Chunker/Indexer Field Mismatch","description":"chunker.py produces 'chunk_index' field, indexer.py expects 'index'. Requires manual JSON field rename after chunking. Fix: harmonize field names in either chunker.py:enrich_chunks() or indexer.py:load_chunks_json()","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T02:55:52.927865+01:00","updated_at":"2026-01-03T03:40:34.050934+01:00","closed_at":"2026-01-03T03:40:34.050934+01:00","close_reason":"Fixed: chunker.py now uses 'index' instead of 'chunk_index' to match indexer.py expectations"}
{"id":"RAG-sgg","title":"RAG Indexing: llama.cpp Stability","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-29T15:59:45.17265+01:00","updated_at":"2025-12-30T00:03:15.336751+01:00","closed_at":"2025-12-30T00:03:15.336751+01:00","close_reason":"Fixed llama.cpp crash: -ub 4096, token-based truncation, delete_source() for duplicates, removed legacy code","comments":[{"id":3,"issue_id":"RAG-sgg","author":"brunowinter2000","text":"llama.cpp embedding server crashes after ~220 requests. Issues:\n1. Server crashes mid-indexing (222/413 chunks)\n2. Abort trap 6 on large batches\n3. Need retry logic or chunked restart\n\nWorkarounds tried:\n- BATCH_SIZE=1\n- MAX_CHUNK_CHARS=2000 truncation\n- Server restart between runs\n\nNext steps:\n- Add retry with server restart\n- Or use different embedding backend (Ollama?)\n- Or batch with sleep between requests","created_at":"2025-12-29T14:59:56Z"},{"id":4,"issue_id":"RAG-sgg","author":"brunowinter2000","text":"## Investigation Notes (2025-12-29)\n\n### Symptom\n- llama-server crashes after ~200-220 embedding requests\n- Error: httpx.RemoteProtocolError: Server disconnected without sending a response\n- Happens consistently during batch indexing\n\n### Server Config\n- Model: Qwen3-Embedding-8B-Q5_K_M.gguf (5GB)\n- Command: llama-server -m model.gguf --embedding --host 0.0.0.0 --port 8081\n- Auto-config: n_ctx=40960, n_slots=4, n_batch=512\n\n### Memory Usage (from startup logs)\n- Model buffer: 5165 MiB (Metal) + 486 MiB (CPU)\n- KV Cache: 5760 MiB (seems excessive for embedding-only mode)\n- Total: ~11GB just for model + KV cache\n\n### Hypothesis\n1. KV cache fills up despite embedding mode (shouldn't need KV cache)\n2. Memory leak in llama.cpp embedding endpoint\n3. n_ctx=40960 is overkill, causing memory pressure\n\n### Potential Fixes to Test\n1. Set smaller n_ctx (e.g. --ctx-size 2048)\n2. Disable KV cache if possible for embeddings\n3. Reduce n_slots (--parallel 1)\n4. Check llama.cpp issues for embedding server memory leaks\n\n### Workaround Implemented\n- embedder.py: Auto-restart on crash (MAX_RESTART_ATTEMPTS=10)\n- Added RemoteProtocolError to exception handling\n- Works but ugly - need root cause fix","created_at":"2025-12-29T17:43:42Z"},{"id":5,"issue_id":"RAG-sgg","author":"brunowinter2000","text":"## Update (2025-12-29)\n\nWorkaround (auto-restart) REVERTED - nicht der richtige Ansatz.\n\nNächster Schritt: Root Cause Investigation\n- Warum crashed llama-server nach ~200 Requests?\n- KV Cache 5.7GB trotz embedding-only mode - verdächtig\n- Test mit --ctx-size 2048 --parallel 1\n- llama.cpp GitHub Issues checken","created_at":"2025-12-29T20:01:48Z"}]}
{"id":"RAG-snl","title":"Ingest Noise Filter","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-02T21:15:25.321598+01:00","updated_at":"2026-01-03T00:52:06.216667+01:00","closed_at":"2026-01-03T00:52:06.216667+01:00","close_reason":"Merged into RAG-qj3 (Cleanup Pipeline Improvement)","comments":[{"id":15,"issue_id":"RAG-snl","author":"brunowinter2000","text":"Filter noise during ingest: Copyright pages, Index, Preface, TOC. Either blacklist patterns or flag metadata so retriever can exclude them. Reduces wasted top_k slots.","created_at":"2026-01-02T20:15:35Z"}]}
{"id":"RAG-vlw","title":"Metadata Injection: Page Numbers","description":"PDF Ingestion muss Seitenzahl als Metadatum speichern. Return-Payload: {content, source, meta: {page, chapter}}. Eliminiert manuelles Verifizieren. Source: Session Evaluation","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:51:29.12095+01:00","updated_at":"2026-01-05T03:51:29.12095+01:00"}
{"id":"RAG-vua","title":"Native arm64 llama.cpp Image","description":"amd64 Image läuft unter Rosetta-Emulation, sehr langsam. Natives arm64 Image bauen oder llama.cpp lokal kompilieren für Performance.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T17:45:18.239819+01:00","updated_at":"2025-12-28T23:21:11.70948+01:00","closed_at":"2025-12-28T23:21:11.70948+01:00","close_reason":"Native Metal GPU build funktioniert, 300x Performance-Gewinn (0.18s vs 60s+)"}
{"id":"RAG-wzj","title":"Unique Anchor Extraction: Ctrl+F optimized output","description":"MCP liefert pro Result einen 'unique anchor' für Ctrl+F. Problem: Generische Zitate ('The optimizer chooses...') haben 50 Treffer im PDF. Lösung: Server prüft via TF-IDF/Heuristik welche Phrase im Chunk selten im Gesamtdokument vorkommt. Output: {content: '...', ctrl_f_anchor: 'cost units that are arbitrary'}. Agent kann sagen: 'Suche nach X, kommt nur einmal vor'. Beschleunigt manuelle Verifikation.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-04T03:06:34.926838+01:00","updated_at":"2026-01-04T03:06:34.926838+01:00"}
{"id":"RAG-xxg","title":"md-cleanup Polish: Attitude section + Python template","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-02T02:40:08.820074+01:00","updated_at":"2026-01-02T02:40:58.985692+01:00","closed_at":"2026-01-02T02:40:58.985692+01:00","close_reason":"Attitude section added to md-cleanup.md"}
{"id":"RAG-z1b","title":"Table Processing: JSON statt Fließtext","description":"Tabellen als JSON mit Key-Value Pairs chunken statt Fließtext. Simple tables → JSON structure, complex tables → Markdown + structural metadata. Dual embedding: JSON + natural language description. Source: Reddit Enterprise RAG Thread","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-05T03:50:53.936012+01:00","updated_at":"2026-01-05T03:50:53.936012+01:00"}
{"id":"RAG-zbl","title":"Mineru output path cleanup","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T01:41:51.390746+01:00","updated_at":"2026-01-03T03:19:01.391322+01:00","closed_at":"2026-01-03T03:19:01.391322+01:00","close_reason":"Added clear_temp_output() in Mineru workflow.py - clears /Mineru/output/ after each successful PDF conversion","comments":[{"id":9,"issue_id":"RAG-zbl","author":"brunowinter2000","text":"Mineru creates output in ${MINERU_PATH}/output/ but should ONLY output to RAG/data/documents/{stem}/raw/. Either delete the Mineru output folder or ensure the workflow clears it after each run.","created_at":"2026-01-02T00:41:58Z"}]}
